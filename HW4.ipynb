{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ⅰ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "t = np.random.normal(0, 50, 50)\n",
    "X = np.array([np.ones_like(t), t, t**2]).T\n",
    "\n",
    "def func(a, b, c, mu, sigma):\n",
    "    return lambda x: a + b * x + c * x**2 + np.random.normal(mu, sigma, x.size)\n",
    "\n",
    "f = func(10, 1, 2, 0, 0.01)\n",
    "Y = f(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \\beta_1的t值\n",
    "from sklearn.linear_model import LinearRegression \n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(X, Y)\n",
    "beta_1 = model.coef_[1]\n",
    "\n",
    "sigma = (Y - model.predict(X)).std(ddof=3)\n",
    "model_2 = LinearRegression(fit_intercept=False)\n",
    "model_2.fit(X[:, [0,2]], X[:, 1])\n",
    "R2 = model_2.score(X[:, [0,2]], X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t值为： 41210.38065847728 临界值为： 2.0117405104757546\n",
      "p值为： 2.8351052596617946e-179 显著水平为： 0.05\n",
      "故拒绝原假设，认为beta_1不等于0\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "# H0: \\beta_1 = 0  \n",
    "t = beta_1 / (sigma / X[:, 1].std() / np.sqrt(X.shape[0] * (1 - R2)))\n",
    "# 根据显著水平计算临界值\n",
    "alpha = 0.05\n",
    "t_critical = stats.t.ppf(1 - alpha / 2, df=X.shape[0] - 3)\n",
    "print('t值为：', t, '临界值为：', t_critical)\n",
    "\n",
    "# 根据计算值给出显著水平\n",
    "p = stats.t.sf(np.abs(t), df=X.shape[0] - 3) * 2\n",
    "print('p值为：', p, '显著水平为：', alpha)\n",
    "\n",
    "print(\"故拒绝原假设，认为beta_1不等于0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t值为： -0.7782161147739707 临界值为： 2.0117405104757546\n",
      "p值为： 0.4403418875923616 显著水平为： 0.05\n",
      "故接受原假设，认为beta_1等于1\n"
     ]
    }
   ],
   "source": [
    "# H0: \\beta_1 = 1\n",
    "t = (beta_1 - 1) / (sigma / X[:, 1].std() / np.sqrt(X.shape[0] * (1 - R2)))\n",
    "# 根据显著水平计算临界值\n",
    "alpha = 0.05\n",
    "t_critical = stats.t.ppf(1 - alpha / 2, df=X.shape[0] - 3)\n",
    "print('t值为：', t, '临界值为：', t_critical)\n",
    "\n",
    "# 根据计算值给出显著水平\n",
    "p = stats.t.sf(np.abs(t), df=X.shape[0] - 3) * 2\n",
    "print('p值为：', p, '显著水平为：', alpha)\n",
    "\n",
    "print(\"故接受原假设，认为beta_1等于1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rc为： 0.9999999999990038\n",
      "Ruc为： 0.9999999999992728\n",
      "Adjusted Rc为： 0.9999999999989614\n",
      "残差平方和为： 0.003494825304884599\n",
      "sigma^2的无偏估计为： 7.435798521031061e-05\n"
     ]
    }
   ],
   "source": [
    "# 拟合优度\n",
    "SSR = ((model.predict(X) - Y)**2).sum()\n",
    "SST = ((Y - Y.mean())**2).sum()\n",
    "uSST = (Y**2).sum()\n",
    "print('Rc为：', 1 - SSR / SST)\n",
    "print('Ruc为：', 1 - SSR / uSST)\n",
    "print('Adjusted Rc为：', 1 - (SSR/(X.shape[0] - 3)) / (SST/(X.shape[0] - 1)))\n",
    "\n",
    "print('残差平方和为：', SSR)\n",
    "print('sigma^2的无偏估计为：', SSR / (X.shape[0] - 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>2.359e+13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 05 Oct 2023</td> <th>  Prob (F-statistic):</th> <td>9.15e-283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:35:13</td>     <th>  Log-Likelihood:    </th> <td>  168.27</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>  -330.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>  -324.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   10.0022</td> <td>    0.001</td> <td> 7008.954</td> <td> 0.000</td> <td>    9.999</td> <td>   10.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.0000</td> <td> 2.43e-05</td> <td> 4.12e+04</td> <td> 0.000</td> <td>    1.000</td> <td>    1.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    2.0000</td> <td> 2.92e-07</td> <td> 6.86e+06</td> <td> 0.000</td> <td>    2.000</td> <td>    2.000</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.597</td> <th>  Durbin-Watson:     </th> <td>   2.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.742</td> <th>  Jarque-Bera (JB):  </th> <td>   0.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.145</td> <th>  Prob(JB):          </th> <td>   0.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.124</td> <th>  Cond. No.          </th> <td>5.73e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.73e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 2.359e+13\n",
       "Date:                Thu, 05 Oct 2023   Prob (F-statistic):          9.15e-283\n",
       "Time:                        16:35:13   Log-Likelihood:                 168.27\n",
       "No. Observations:                  50   AIC:                            -330.5\n",
       "Df Residuals:                      47   BIC:                            -324.8\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         10.0022      0.001   7008.954      0.000       9.999      10.005\n",
       "x1             1.0000   2.43e-05   4.12e+04      0.000       1.000       1.000\n",
       "x2             2.0000   2.92e-07   6.86e+06      0.000       2.000       2.000\n",
       "==============================================================================\n",
       "Omnibus:                        0.597   Durbin-Watson:                   2.124\n",
       "Prob(Omnibus):                  0.742   Jarque-Bera (JB):                0.207\n",
       "Skew:                           0.145   Prob(JB):                        0.902\n",
       "Kurtosis:                       3.124   Cond. No.                     5.73e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.73e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "sm_model = sm.OLS(Y, X).fit()\n",
    "sm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999990038\n",
      "0.9999999999989614\n"
     ]
    }
   ],
   "source": [
    "# 使用的是Rc，当然也有adjusted Rc\n",
    "print(sm_model.rsquared)\n",
    "print(sm_model.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ⅱ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-50, 50, 101)\n",
    "y = 1 + 0.5 * x + np.random.normal(0, 1, 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H0: alpha_1 + alpha_2 = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于Wald统计量，我们知道：\n",
    "$$\n",
    "(1^T \\alpha - 1.5)^T (Var(1^T \\alpha))^{-1} (1^T \\alpha - 1.5) \\sim \\chi^2(1)\n",
    "$$\n",
    "其中：\n",
    "$$\n",
    "1 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "\\alpha = \\begin{bmatrix} \\alpha_2 \\\\ \\alpha_2 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "同时我们知道：\n",
    "\\begin{align*}\n",
    "Var(1^T \\alpha) &= 1^T Var(\\alpha) 1 \\\\\n",
    "&= \\sigma^2 1^T(X^T X)^{-1} 1 \\\\\n",
    "\\end{align*} \n",
    "\n",
    "且我们可以估计$\\sigma^2$：\n",
    "$$\n",
    "\\hat{\\sigma}^2 = \\frac{1}{n-2} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "更进一步，我们知道：\n",
    "$$\n",
    "\\frac{(n-2)\\hat{\\sigma}^2 }{\\sigma^2} \\sim \\chi^2(n-2)\n",
    "$$\n",
    "\n",
    "所以有：\n",
    "$$\n",
    "\\frac{\n",
    "    (1^T \\alpha - 1.5)^T (1^T(X^T X)^{-1} 1)^{-1} (1^T \\alpha - 1.5) / 1\n",
    "}{\n",
    "    (n-2)\\hat{\\sigma}^2 / (n-2)\n",
    "} \\sim F(1, n-2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代入数据\n",
    "X = np.array([np.ones_like(x), x]).T\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(X, y)\n",
    "alpha = model.coef_\n",
    "sigma2_hat = ((y - model.predict(X))**2).sum() / (X.shape[0] - 2)\n",
    "\n",
    "F_1 = (alpha.sum() - 1.5)**2 / (np.linalg.inv(X.T @ X).sum()) / sigma2_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若是用约束求解问题来看，不妨只考虑带约束的情形：\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\min_{\\alpha} \\quad & ||Y - X\\alpha||^2 \\\\\n",
    "s.t. \\quad & R \\alpha = q\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "使用Lagrange乘子法，我们有：\n",
    "$$\n",
    "\\mathcal{L}(\\alpha, \\lambda) = ||Y - X\\alpha||^2 + (R \\alpha - q)^T \\lambda\n",
    "$$\n",
    "\n",
    "求导得：\n",
    "\\begin{cases}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\alpha} &= -2 X^T Y + 2 X^T X \\alpha + R ^T\\lambda = 0 \\\\\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\lambda} &= R \\alpha - q = 0\n",
    "\\end{cases}\n",
    "\n",
    "将1式两侧同时左乘$\\frac{1}{2}R(X^T X)^{-1}$并，得：\n",
    "$$\n",
    "q = R\\alpha = R(X^T X)^{-1} X^T Y - \\frac{1}{2} R(X^T X)^{-1} R^T \\lambda\n",
    "$$\n",
    "\n",
    "进而解得：\n",
    "$$\n",
    "\\frac{\\lambda}{2} = (R(X^T X)^{-1} R^T)^{-1} (R(X^T X)^{-1} X^T Y - q)\n",
    "$$\n",
    "\n",
    "代回1式，得：\n",
    "$$\n",
    "\\alpha = (X^T X)^{-1} X^T Y - (X^T X)^{-1} R^T (R(X^T X)^{-1} R^T)^{-1} (R(X^T X)^{-1} X^T Y - q)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们用$\\beta$表示无约束估计的解，那么上式可以写成：\n",
    "$$\n",
    "\\alpha = \\beta - (X^T X)^{-1} R^T (R(X^T X)^{-1} R^T)^{-1} (R\\beta - q)\n",
    "$$\n",
    "\n",
    "在该估计下的SSR为：\n",
    "$$\n",
    "\\begin{align*}\n",
    "SSR(\\alpha) &= (Y - X\\alpha)^T (Y - X\\alpha) \\\\\n",
    "&= (Y - X\\beta + X\\beta - X\\alpha)^T (Y - X\\beta + X\\beta - X\\alpha) \\\\\n",
    "&= (Y - X\\beta)^T (Y - X\\beta) + (X\\beta - X\\alpha)^T (X\\beta - X\\alpha) \\\\\n",
    "&= SSR(\\beta) + (X\\beta - X\\alpha)^T (X\\beta - X\\alpha) \\\\\n",
    "&= SSR(\\beta) + (\\beta - \\alpha)^T X^T X (\\beta - \\alpha) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "我们发现有：\n",
    "$$\n",
    "\\begin{align*}\n",
    "SSR(\\alpha) - SSR(\\beta) &= (\\beta - \\alpha)^T X^T X (\\beta - \\alpha) \\\\\n",
    "&= ((X^T X)^{-1} R^T (R(X^T X)^{-1} R^T)^{-1} (R\\beta - q))^T X^T X ((X^T X)^{-1} R^T (R(X^T X)^{-1} R^T)^{-1} (R\\beta - q)) \\\\\n",
    "&= (R\\beta - q)^T (R(X^T X)^{-1} R^T)^{-1} R (X^T X)^{-1} R^T (R(X^T X)^{-1} R^T)^{-1} (R\\beta - q) \\\\\n",
    "&= (R\\beta - q)^T (R(X^T X)^{-1} R^T)^{-1} (R\\beta - q) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "故方法1中的Wald统计量可以写成：\n",
    "$$\n",
    "F= \\frac{(SSR(\\alpha) - SSR(\\beta)) / J}{\\hat{\\sigma}^2} = \\frac{(SSR(\\alpha) - SSR(\\beta)) / J}{SSR(\\beta) / (n - p)} \n",
    "= \\frac{R^2(\\beta) - R^2(\\alpha)}{1 - R^2(\\beta)} \\frac{n - p}{J}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代入数据\n",
    "model_2 = LinearRegression(fit_intercept=False)\n",
    "X_2 = x - 1\n",
    "Y_2 = y - 1.5\n",
    "model_2.fit(X_2.reshape(-1, 1), Y_2)\n",
    "\n",
    "R2_1 = model.score(X, y)\n",
    "R2_2 = model_2.score(X_2.reshape(-1, 1), Y_2)\n",
    "F_2 = (R2_1 - R2_2) / (1 - R2_1) * (x.size - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_1为： 0.05581708146678345\n",
      "F_2为： 0.05581708146752701\n",
      "在显著性水平为5%时，临界值为： 3.937116910962888 故接受原假设\n"
     ]
    }
   ],
   "source": [
    "print('F_1为：', F_1)\n",
    "print('F_2为：', F_2)\n",
    "print('在显著性水平为5%时，临界值为：', stats.f.ppf(1 - 0.05, 1, x.size - 2), '故接受原假设')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H0: alpha_1 + alpha_2 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代入数据\n",
    "X = np.array([np.ones_like(x), x]).T\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(X, y)\n",
    "alpha = model.coef_\n",
    "sigma2_hat = ((y - model.predict(X))**2).sum() / (X.shape[0] - 2)\n",
    "\n",
    "F_1 = (alpha.sum() - 10)**2 / (np.linalg.inv(X.T @ X).sum()) / sigma2_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代入数据\n",
    "model_2 = LinearRegression(fit_intercept=False)\n",
    "X_2 = x - 1\n",
    "Y_2 = y - 10\n",
    "model_2.fit(X_2.reshape(-1, 1), Y_2)\n",
    "\n",
    "R2_1 = model.score(X, y)\n",
    "R2_2 = model_2.score(X_2.reshape(-1, 1), Y_2)\n",
    "F_2 = (R2_1 - R2_2) / (1 - R2_1) * (x.size - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_1为： 6964.242508649678\n",
      "F_2为： 6964.242508649698\n",
      "在显著性水平为10%时，临界值为： 2.756898790979433 故拒绝原假设\n"
     ]
    }
   ],
   "source": [
    "print('F_1为：', F_1)\n",
    "print('F_2为：', F_2)\n",
    "print('在显著性水平为10%时，临界值为：', stats.f.ppf(1 - 0.1, 1, x.size - 2), '故拒绝原假设')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ⅲ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('D:\\study\\Math\\时间序列分析\\Data\\iris_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵为： [[11  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  1  5]]\n",
      "分类报告为：\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        11\n",
      "         1.0       0.93      1.00      0.96        13\n",
      "         2.0       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.98      0.94      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split    \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=10, max_depth=5, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1], data.iloc[:, -1], test_size=0.2, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('混淆矩阵为：', confusion_matrix(y_test, model.predict(X_test)))\n",
    "print('分类报告为：\\n', classification_report(y_test, model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ⅳ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"D:\\study\\Math\\时间序列分析\\Data\\MCdata_SH(1).csv\")\n",
    "GDP = data.iloc[:, 1]\n",
    "CPI = data.iloc[:, 2]\n",
    "Invest = data.iloc[:, 3]\n",
    "R = data.iloc[:, 4]\n",
    "\n",
    "T = np.arange(1, GDP.size + 1)\n",
    "G = GDP / CPI\n",
    "Y = Invest / CPI\n",
    "P = CPI.pct_change()\n",
    "P[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([T, G, R, P]).T\n",
    "Y = Y.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型的R方为： 0.9587127838564551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regression', Lasso(alpha=3e-4, random_state=44))\n",
    "])\n",
    "model.fit(X, Y)\n",
    "print(\"模型的R方为：\", model.score(X, Y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
